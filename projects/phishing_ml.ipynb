{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "a8ybwvI7F25L",
        "c002bc92",
        "hxXu-HBXveML",
        "37456ee2",
        "LK3iPeHqGpm8",
        "GXtwY-SaIhOV",
        "mRq6jt9R9Aiy",
        "DTNa7why-TH2"
      ],
      "authorship_tag": "ABX9TyND1TcnILXrc5MBEp9RoLPM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Savvythelegend/MLE/blob/main/projects/phishing_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phishing Website Classification Project"
      ],
      "metadata": {
        "id": "19JPa653fAOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Objective\n",
        "The primary objective of this project is to develop and evaluate various machine learning models capable of classifying websites as either legitimate or phishing based on a given dataset. We will explore different algorithms to identify the most effective approach"
      ],
      "metadata": {
        "id": "iSIEyorEGA0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Loading Data:"
      ],
      "metadata": {
        "id": "a8ybwvI7F25L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f08751c8"
      },
      "source": [
        "#importing basic packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebf87b0d"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Local file path\n",
        "file_path = '/content/Phishing Data - Phishing Data.csv'\n",
        "\n",
        "# If the file is not in Colab, mount Google Drive\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"Local file not found, mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    file_path = '/content/drive/MyDrive/Phishing Data - Phishing Data.csv'\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\"Shape:\", df.shape)\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c002bc92"
      },
      "source": [
        "## 3. Data Preprocessing & EDA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "pEljJSlItyau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "  print(col)"
      ],
      "metadata": {
        "id": "bl-l23HHt5BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMq3enRAeEJw"
      },
      "source": [
        "df.dropna(subset=['Result'], inplace=True)\n",
        "print(\"Missing values per column after dropping rows with missing Result:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "sE-Wb6b7uAc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cbca4d7"
      },
      "source": [
        "### Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aa9f0a0"
      },
      "source": [
        "#plotting the data distribution\n",
        "df.hist(bins=20, figsize=(20, 15))\n",
        "plt.suptitle('Feature Distributions', fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation heatmap\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "plt.figure(figsize=(20, 15))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Features', fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oz2cCwwOtf1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### EDA Result\n",
        "- Classes are fairly balanced.\n",
        "- Features show varying correlation with the target."
      ],
      "metadata": {
        "id": "1RAHkfkF3UvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Result'].value_counts()\n",
        "sns.countplot(x='Result', data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IiDVQXbxuImD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Splitting the Data\n",
        "- Features already numeric, so no encoding needed.\n",
        "- Train-test split with stratification to maintain class balance."
      ],
      "metadata": {
        "id": "hxXu-HBXveML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Result']\n",
        "X = df.drop('Result',axis=1)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "6_rTbydCvqro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "KnxTmJhJvXDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-ABKRixuryD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37456ee2"
      },
      "source": [
        "## 5. Machine Learning Models & Training\n",
        "\n",
        "This is a supervised machine learning task, specifically a classification problem, as the goal is to classify a URL as either phishing (1) or legitimate (0). The following supervised machine learning models will be used to train the dataset:\n",
        "*   Decision Tree\n",
        "*   Random Forest\n",
        "*   Support Vector Machines\n",
        "*   XGBoost\n",
        "*   MLP (Multilayer Perceptrons)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "E_TuXt2CSLmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50061fea"
      },
      "source": [
        "### Model Evaluation Setup\n",
        "\n",
        "*A helper function `storeResults` is defined to store the model name and its training and testing accuracies in lists. These lists will be used later to create a comparison table of the models.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating holders to store the model performance results\n",
        "ML_Model = []\n",
        "acc_train = []\n",
        "acc_test = []\n",
        "\n",
        "#function to call for storing the results\n",
        "def storeResults(model, a,b):\n",
        "  ML_Model.append(model)\n",
        "  acc_train.append(round(a, 3))\n",
        "  acc_test.append(round(b, 3))"
      ],
      "metadata": {
        "id": "ayb-EXwYxxZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c29fff95"
      },
      "source": [
        "### Decision Tree Classifier\n",
        "\n",
        "*The Decision Tree Classifier is a simple yet powerful model that makes decisions based on a tree-like structure*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier(max_depth= 5)\n",
        "tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "G_DQW3d5yJLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_test_tree = tree.predict(X_test)\n",
        "y_train_tree = tree.predict(X_train)"
      ],
      "metadata": {
        "id": "gLBnxEgnzWv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance Evaluation:"
      ],
      "metadata": {
        "id": "0CBvvKQfzg80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#computing the accuracy of the model performance\n",
        "acc_train_tree = accuracy_score(y_train,y_train_tree)\n",
        "acc_test_tree = accuracy_score(y_test,y_test_tree)\n",
        "\n",
        "print(\"Decision Tree: Accuracy on training Data: {:.3f}\".format(acc_train_tree))\n",
        "print(\"Decision Tree: Accuracy on test Data: {:.3f}\".format(acc_test_tree))"
      ],
      "metadata": {
        "id": "0Xv2Jg8kzYdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,7))\n",
        "n_features = X_train.shape[1]\n",
        "plt.barh(range(n_features), tree.feature_importances_, align='center')\n",
        "plt.yticks(np.arange(n_features), X_train.columns)\n",
        "plt.xlabel(\"Feature importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e7kahfTZzkD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Caution: Execute only once to avoid duplications.\n",
        "storeResults('Decision Tree', acc_train_tree, acc_test_tree)"
      ],
      "metadata": {
        "id": "6Br7_G5_0Y4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8922a85"
      },
      "source": [
        "### Random Forest Classifier\n",
        "\n",
        "*The Random Forest Classifier is an ensemble model that combines multiple decision trees to improve prediction accuracy and reduce overfitting.*."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# instantiate the model\n",
        "forest = RandomForestClassifier(max_depth=5)\n",
        "\n",
        "# fit the model\n",
        "forest.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "iBCHgm6-07n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_test_forest = forest.predict(X_test)\n",
        "y_train_forest = forest.predict(X_train)"
      ],
      "metadata": {
        "id": "lIRuXxDT1tMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Performance Evaluation"
      ],
      "metadata": {
        "id": "kh0RAVoi1i9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#computing the accuracy of the model performance\n",
        "acc_train_forest = accuracy_score(y_train,y_train_forest)\n",
        "acc_test_forest = accuracy_score(y_test,y_test_forest)\n",
        "\n",
        "print(\"Random forest: Accuracy on training Data: {:.3f}\".format(acc_train_forest))\n",
        "print(\"Random forest: Accuracy on test Data: {:.3f}\".format(acc_test_forest))"
      ],
      "metadata": {
        "id": "5GoUDpSg1S6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the feature improtance in the model\n",
        "plt.figure(figsize=(9,7))\n",
        "n_features = X_train.shape[1]\n",
        "plt.barh(range(n_features), forest.feature_importances_, align='center')\n",
        "plt.yticks(np.arange(n_features), X_train.columns)\n",
        "plt.xlabel(\"Feature importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YbFtCWt_1n57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storeResults('Random Forest', acc_train_forest, acc_test_forest)"
      ],
      "metadata": {
        "id": "aNZY8qy32cT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be1cf1ef"
      },
      "source": [
        "### Multilayer Perceptrons (MLP) Classifier\n",
        "\n",
        "*The Multilayer Perceptron (MLP) is a type of artificial neural network. We instantiate an `MLPClassifier` with a specified alpha (L2 regularization term) and a few hidden layers with 100 neurons each.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptrons model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# instantiate the model\n",
        "mlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=([100,100,100]))\n",
        "\n",
        "# fit the model\n",
        "mlp.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rh6VS1KW29RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_test_mlp = mlp.predict(X_test)\n",
        "y_train_mlp = mlp.predict(X_train)"
      ],
      "metadata": {
        "id": "3UBlL9-W8DIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Performance Evaluation"
      ],
      "metadata": {
        "id": "kmvYua7vINYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#computing the accuracy of the model performance\n",
        "acc_train_mlp = accuracy_score(y_train,y_train_mlp)\n",
        "acc_test_mlp = accuracy_score(y_test,y_test_mlp)\n",
        "\n",
        "print(\"Multilayer Perceptrons: Accuracy on training Data: {:.3f}\".format(acc_train_mlp))\n",
        "print(\"Multilayer Perceptrons: Accuracy on test Data: {:.3f}\".format(acc_test_mlp))"
      ],
      "metadata": {
        "id": "_8jmlMYM8OnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storeResults('Multilayer Perceptrons',acc_train_mlp, acc_test_mlp)"
      ],
      "metadata": {
        "id": "8MVqntLSHHT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35871a5a"
      },
      "source": [
        "### XGBoost Classifier\n",
        "\n",
        "*XGBoost (Extreme Gradient Boosting) is a powerful and efficient gradient boosting algorithm. We instantiate an `XGBClassifier` with a specified learning rate and maximum depth.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost Classification model\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# instantiate the model\n",
        "xgb = XGBClassifier(learning_rate=0.3, max_depth=7)\n",
        "#fit the model\n",
        "xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "my-TJI5k8QNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_test_xgb = xgb.predict(X_test)\n",
        "y_train_xgb = xgb.predict(X_train)"
      ],
      "metadata": {
        "id": "Lgvrabra-6Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Performance Evaluation"
      ],
      "metadata": {
        "id": "qwEDWWWlIPYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#computing the accuracy of the model performance\n",
        "acc_train_xgb = accuracy_score(y_train,y_train_xgb)\n",
        "acc_test_xgb = accuracy_score(y_test,y_test_xgb)\n",
        "\n",
        "print(\"XGBoost: Accuracy on training Data: {:.3f}\".format(acc_train_xgb))\n",
        "print(\"XGBoost : Accuracy on test Data: {:.3f}\".format(acc_test_xgb))"
      ],
      "metadata": {
        "id": "EZxWbf7Z_G10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storeResults('XGBoost', acc_train_xgb, acc_test_xgb)"
      ],
      "metadata": {
        "id": "c0q5En45_JGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4408875d"
      },
      "source": [
        "### Support Vector Machine (SVM) Classifier\n",
        "\n",
        "*The Support Vector Machine (SVM) is a versatile model that can be used for both classification and regression. We instantiate two `SVC` models, one with a linear kernel and another with an RBF kernel, to explore different decision boundaries.*\n",
        "\n",
        "Both models are trained on the training data and we'll keep track of one with better accuracy out of both"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Support vector machine model (linear kernel)\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# instantiate the model\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=12)\n",
        "#fit the model\n",
        "svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "WJeJVK9H_NK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_test_svm = svm.predict(X_test)\n",
        "y_train_svm = svm.predict(X_train)"
      ],
      "metadata": {
        "id": "8CB3GU5QFRNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance Evaluation"
      ],
      "metadata": {
        "id": "zUmofgLMIlO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#computing the accuracy of the model performance\n",
        "acc_train_svm = accuracy_score(y_train,y_train_svm)\n",
        "acc_test_svm = accuracy_score(y_test,y_test_svm)\n",
        "\n",
        "print(\"SVM: Accuracy on training Data: {:.3f}\".format(acc_train_svm))\n",
        "print(\"SVM : Accuracy on test Data: {:.3f}\".format(acc_test_svm))"
      ],
      "metadata": {
        "id": "n2mx1hg9FUNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Support vector machine model (kernel -> rbf)\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# instantiate the model\n",
        "svm1 = SVC(kernel='rbf', C=1.0, random_state=12) # c for penality\n",
        "#fit the model\n",
        "svm1.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "N9-0QTqoFOEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_test_svm = svm1.predict(X_test)\n",
        "y_train_svm = svm1.predict(X_train)"
      ],
      "metadata": {
        "id": "K015qLBfFZK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance Evaluation"
      ],
      "metadata": {
        "id": "Fux2C4PbIoRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#computing the accuracy of the model performance\n",
        "acc_train_svm = accuracy_score(y_train,y_train_svm)\n",
        "acc_test_svm = accuracy_score(y_test,y_test_svm)\n",
        "\n",
        "print(\"SVM: Accuracy on training Data: {:.3f}\".format(acc_train_svm))\n",
        "print(\"SVM : Accuracy on test Data: {:.3f}\".format(acc_test_svm))"
      ],
      "metadata": {
        "id": "ql6ygtGMFf5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Storing the result for svm (rbf)\n",
        "The fact that the **RBF kernel** outperformed the linear kernel on your dataset suggests that the relationship between the features of phishing websites and legitimate ones is **non-linear**.\n",
        "\n",
        "*There is no single straight line that can perfectly separate the two classes, and the RBF kernel was able to learn the curved boundaries that better fit data.*"
      ],
      "metadata": {
        "id": "k4GZLesb7JKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storeResults('SVM', acc_train_svm, acc_test_svm)"
      ],
      "metadata": {
        "id": "qRIsvBYaF2J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Comparision of Models\n",
        "To compare the models performance, a dataframe is created. The columns of this dataframe are the lists created to store the results of the model."
      ],
      "metadata": {
        "id": "LK3iPeHqGpm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({ 'ML Model': ML_Model,\n",
        "    'Train Accuracy': acc_train,\n",
        "    'Test Accuracy': acc_test})\n",
        "results"
      ],
      "metadata": {
        "id": "n0kDZJ3jGqi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For the above comparision\n",
        "*it is clear that the **XGBoost Classifier** works well with this dataset.* ðŸ‘‘"
      ],
      "metadata": {
        "id": "GXtwY-SaIhOV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tbX_XJ-CtMQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Saving the model - *XGBoost*"
      ],
      "metadata": {
        "id": "mRq6jt9R9Aiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(xgb, 'xgb_phishing_ml.joblib')\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "RHGIqBjWRDHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Evaluation and Conclusion\n",
        "\n",
        "\n",
        "> 1. Evaluation\n",
        "> 2. Feature importance\n",
        "> 3. Hyperparameter tuning\n",
        "> 4. Summary\n"
      ],
      "metadata": {
        "id": "DTNa7why-TH2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5YXEZBpORM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RT4CkcRQOR_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Evaluation"
      ],
      "metadata": {
        "id": "3pIzsUVvHcrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "JbK-DxNT-T3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - XGBoost\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g4M8q85bI4KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix shows that the XGBoost model performs very well in detecting phishing websites.  \n",
        "- It correctly classifies the majority of both legitimate (254) and phishing (223) websites.  \n",
        "- Only 8 legitimate sites were wrongly flagged as phishing (false positives).  \n",
        "- Only 7 phishing sites were missed and classified as legitimate (false negatives).  \n",
        "\n",
        "*This indicates a strong balance between **precision** and **recall**, making the model reliable for real-world use.*"
      ],
      "metadata": {
        "id": "WCLbUzyBJvvB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xE2JGagqJuIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmmSDfElJ65M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Feature importance"
      ],
      "metadata": {
        "id": "7pWmEg4gKGDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = xgb.feature_importances_\n",
        "feat_imp = pd.Series(importances, index=X_train.columns).sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=feat_imp.values[:15], y=feat_imp.index[:15])\n",
        "plt.title(\"Top 15 Feature Importances - XGBoost\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "glx6dRqkJ7SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z5bRirpaKPPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYp5_Ek7L1M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Hyperparameter tuning"
      ],
      "metadata": {
        "id": "qd4ACv6POIwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Define parameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [3, 4, 5, 6, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.4],\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2, 0.3],\n",
        "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
        "    'reg_lambda': [1, 1.5, 2, 3]\n",
        "}\n",
        "\n",
        "# Base model\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# RandomizedSearch\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,  # number of random combinations to try\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "print(\"Best cross-validation score:\", random_search.best_score_)\n",
        "\n",
        "# Refit the model with best parameters\n",
        "best_xgb = random_search.best_estimator_"
      ],
      "metadata": {
        "id": "5tFdNXbRL2n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb = XGBClassifier(\n",
        "    subsample=0.6,\n",
        "    reg_lambda=1.5,\n",
        "    reg_alpha=0,\n",
        "    n_estimators=200,\n",
        "    max_depth=7,\n",
        "    learning_rate=0.2,\n",
        "    gamma=0,\n",
        "    colsample_bytree=1.0,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "best_xgb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "print(\"Test Accuracy:\", np.round(accuracy_score(y_test, y_pred),3))\n"
      ],
      "metadata": {
        "id": "ndqbMkZ8MLLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Summary**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eUjNC0XEOU_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project successfully developed an **XGBoost Classifier** that achieved approximately **97% accuracy** in detecting phishing websites. This model was chosen for its superior performance and balanced precision and recall, demonstrating its reliability."
      ],
      "metadata": {
        "id": "cNB868zjOCEh"
      }
    }
  ]
}